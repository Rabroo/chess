{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Chess Evaluation LLM\n",
    "\n",
    "Fine-tune LLMs to predict chess position evaluations from FEN strings.\n",
    "\n",
    "**Features:**\n",
    "- Streams data from Lichess (depth 60+ evaluations)\n",
    "- Uses Unsloth for 2x faster training\n",
    "- Multiple model options (Llama, Mistral, Phi, Qwen)\n",
    "\n",
    "**Runtime:** Select GPU: `Runtime → Change runtime type → T4 GPU` (or A100 for larger models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "!pip install --no-deps trl peft accelerate bitsandbytes\n",
    "!apt-get install -qq zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Data settings\n",
    "NUM_POSITIONS = 50000      # Start small, increase to 500K-1M for better results\n",
    "MIN_DEPTH = 40             # Minimum Stockfish depth (40-60 recommended)\n",
    "\n",
    "# Model selection (uncomment one)\n",
    "# For T4 (16GB) - use smaller models:\n",
    "MODEL_NAME = \"unsloth/Phi-3.5-mini-instruct\"  # 3.8B - fast, good quality\n",
    "# MODEL_NAME = \"unsloth/Llama-3.2-3B-Instruct\"  # 3B - good balance\n",
    "# MODEL_NAME = \"unsloth/Qwen2.5-3B-Instruct\"    # 3B - multilingual\n",
    "# MODEL_NAME = \"unsloth/mistral-7b-instruct-v0.3\"  # 7B - needs more VRAM\n",
    "\n",
    "# For A100 (40GB) - can use larger models:\n",
    "# MODEL_NAME = \"unsloth/Llama-3.1-8B-Instruct\"  # 8B\n",
    "# MODEL_NAME = \"unsloth/Qwen2.5-7B-Instruct\"    # 7B\n",
    "\n",
    "# Training settings\n",
    "MAX_SEQ_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# LoRA settings\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 16\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Positions: {NUM_POSITIONS:,}\")\n",
    "print(f\"Min depth: {MIN_DEPTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "LICHESS_EVAL_URL = \"https://database.lichess.org/lichess_db_eval.jsonl.zst\"\n",
    "\n",
    "def score_to_description(score_cp):\n",
    "    \"\"\"Convert centipawn score to description.\"\"\"\n",
    "    pawns = score_cp / 100\n",
    "    if score_cp > 900:\n",
    "        return f\"White is winning\"\n",
    "    elif score_cp > 300:\n",
    "        return f\"White has a significant advantage\"\n",
    "    elif score_cp > 100:\n",
    "        return f\"White has a slight advantage\"\n",
    "    elif score_cp > -100:\n",
    "        return f\"The position is roughly equal\"\n",
    "    elif score_cp > -300:\n",
    "        return f\"Black has a slight advantage\"\n",
    "    elif score_cp > -900:\n",
    "        return f\"Black has a significant advantage\"\n",
    "    else:\n",
    "        return f\"Black is winning\"\n",
    "\n",
    "def stream_lichess_data(limit, min_depth):\n",
    "    \"\"\"Stream and format data from Lichess.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(f\"Streaming Lichess evaluations (depth >= {min_depth})...\")\n",
    "    print(\"This may take 10-30 minutes...\\n\")\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        f'curl -sL \"{LICHESS_EVAL_URL}\" | zstd -d',\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    processed = 0\n",
    "    last_print = 0\n",
    "    \n",
    "    instructions = [\n",
    "        \"Evaluate this chess position.\",\n",
    "        \"What is the evaluation of this chess position?\",\n",
    "        \"Analyze this position and give a score.\",\n",
    "        \"Score this chess position in centipawns.\",\n",
    "    ]\n",
    "    \n",
    "    for line in process.stdout:\n",
    "        if len(data) >= limit:\n",
    "            break\n",
    "            \n",
    "        processed += 1\n",
    "        \n",
    "        if processed - last_print >= 10000:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = processed / elapsed\n",
    "            print(f\"\\rProcessed: {processed:,} | Found: {len(data):,}/{limit:,} | {rate:.0f}/s\", end=\"\")\n",
    "            last_print = processed\n",
    "        \n",
    "        try:\n",
    "            entry = json.loads(line.strip())\n",
    "            fen = entry.get(\"fen\")\n",
    "            evals = entry.get(\"evals\", [])\n",
    "            \n",
    "            if not fen or not evals:\n",
    "                continue\n",
    "            \n",
    "            best_eval = max(evals, key=lambda e: e.get(\"depth\", 0))\n",
    "            depth = best_eval.get(\"depth\", 0)\n",
    "            \n",
    "            if depth < min_depth:\n",
    "                continue\n",
    "            \n",
    "            pvs = best_eval.get(\"pvs\", [])\n",
    "            if not pvs:\n",
    "                continue\n",
    "            \n",
    "            pv = pvs[0]\n",
    "            if \"cp\" in pv:\n",
    "                score_cp = pv[\"cp\"]\n",
    "            elif \"mate\" in pv:\n",
    "                continue  # Skip mates for cleaner training\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if abs(score_cp) > 5000:\n",
    "                continue\n",
    "            \n",
    "            # Format for training\n",
    "            instruction = random.choice(instructions)\n",
    "            pawns = score_cp / 100\n",
    "            description = score_to_description(score_cp)\n",
    "            \n",
    "            text = f\"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{fen}\n",
    "\n",
    "### Response:\n",
    "Evaluation: {score_cp} centipawns ({pawns:+.2f} pawns)\n",
    "{description}.\n",
    "Depth: {depth}\"\"\"\n",
    "            \n",
    "            data.append({\"text\": text})\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    process.terminate()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n\\nExtracted {len(data):,} positions in {elapsed:.1f}s\")\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "# Download data\n",
    "train_data = stream_lichess_data(NUM_POSITIONS, MIN_DEPTH)\n",
    "print(f\"\\nSample:\\n{train_data[0]['text'][:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Model with Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,  # Auto-detect\n",
    "    load_in_4bit=True,  # Use 4-bit quantization for memory efficiency\n",
    ")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {MODEL_NAME}\")\n",
    "print(f\"Trainable parameters: {model.print_trainable_parameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "dataset = Dataset.from_list(train_data)\n",
    "\n",
    "# Split into train/val\n",
    "split = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = split[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train_dataset):,}\")\n",
    "print(f\"Val: {len(val_dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./chess_llm_output\",\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
    "        warmup_steps=50,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        logging_steps=25,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=200,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Total time: {trainer_stats.metrics['train_runtime'] / 60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test positions\n",
    "test_positions = [\n",
    "    (\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\", \"Starting position\"),\n",
    "    (\"rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1\", \"After 1.e4\"),\n",
    "    (\"r1bqkb1r/pppp1ppp/2n2n2/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 4 4\", \"Italian Game\"),\n",
    "    (\"8/8/8/8/8/5K2/4Q3/7k w - - 0 1\", \"K+Q vs K (winning)\"),\n",
    "    (\"rnbqkb1r/pppp1ppp/5n2/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 3 3\", \"Scholar's Mate threat\"),\n",
    "]\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"Testing model predictions:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fen, description in test_positions:\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Evaluate this chess position.\n",
    "\n",
    "### Input:\n",
    "{fen}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response.split(\"### Response:\")[-1].strip()\n",
    "    \n",
    "    print(f\"Position: {description}\")\n",
    "    print(f\"FEN: {fen[:40]}...\")\n",
    "    print(f\"Prediction: {response[:150]}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA adapters locally\n",
    "model.save_pretrained(\"chess_llm_lora\")\n",
    "tokenizer.save_pretrained(\"chess_llm_lora\")\n",
    "print(\"Saved LoRA adapters to: chess_llm_lora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/chess_llm_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Copy LoRA adapters\n",
    "shutil.copytree(\"chess_llm_lora\", f\"{save_dir}/chess_llm_lora\", dirs_exist_ok=True)\n",
    "print(f\"Saved to Google Drive: {save_dir}/chess_llm_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Merge and save full model (larger, but no base model needed)\n",
    "SAVE_MERGED = False  # Set to True if you want the full model\n",
    "\n",
    "if SAVE_MERGED:\n",
    "    model.save_pretrained_merged(\n",
    "        \"chess_llm_merged\",\n",
    "        tokenizer,\n",
    "        save_method=\"merged_16bit\",\n",
    "    )\n",
    "    print(\"Saved merged model to: chess_llm_merged/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional: Push to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if you want to push to HF Hub\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"YOUR_HF_TOKEN\")\n",
    "\n",
    "# model.push_to_hub(\"your-username/chess-eval-llm\")\n",
    "# tokenizer.push_to_hub(\"your-username/chess-eval-llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Multiple Models\n",
    "\n",
    "To train multiple models, restart runtime and change `MODEL_NAME` to:\n",
    "- `unsloth/Phi-3.5-mini-instruct` (3.8B)\n",
    "- `unsloth/Llama-3.2-3B-Instruct` (3B)\n",
    "- `unsloth/Qwen2.5-3B-Instruct` (3B)\n",
    "- `unsloth/mistral-7b-instruct-v0.3` (7B, needs more VRAM)\n",
    "\n",
    "Then compare their predictions on the same test positions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
